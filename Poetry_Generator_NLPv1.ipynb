{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Efi-Pecani/poetry_generation/blob/main/Poetry_Generator_NLPv1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLh8z_hEUCTY"
      },
      "source": [
        "import numpy as np\n",
        "import string\n",
        "\n",
        "np.random.seed(1234)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TR6uHGtBUbFm"
      },
      "source": [
        "initial = {} # start of a phrase\n",
        "first_order = {} # second word only\n",
        "second_order = {}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNP9na4yUelU"
      },
      "source": [
        "def remove_punctuation(s):\n",
        "    return s.translate(str.maketrans('','',string.punctuation))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jknIxRKzUhwc",
        "outputId": "0f076a38-efeb-453d-fbad-924ac76aa463"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-19 20:00:30--  https://raw.githubusercontent.com/lazyprogrammer/machine_learning_examples/master/hmm_class/robert_frost.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 56286 (55K) [text/plain]\n",
            "Saving to: ‘robert_frost.txt’\n",
            "\n",
            "\rrobert_frost.txt      0%[                    ]       0  --.-KB/s               \rrobert_frost.txt    100%[===================>]  54.97K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-09-19 20:00:30 (55.8 MB/s) - ‘robert_frost.txt’ saved [56286/56286]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S0mbp9FPUk4o"
      },
      "source": [
        "def add2dict(d, k, v):\n",
        "  if k not in d:\n",
        "    d[k] = []\n",
        "  d[k].append(v)\n",
        "\n",
        "# [cat, cat, dog, dog, dog, dog, dog, mouse, ...]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FoBDJVw3UrbE"
      },
      "source": [
        "for line in open('robert_frost.txt'):\n",
        "  tokens = remove_punctuation(line.rstrip().lower()).split()\n",
        "\n",
        "  T = len(tokens)\n",
        "  for i in range(T):\n",
        "    t = tokens[i]\n",
        "    if i == 0:\n",
        "      # measure the distribution of the first word\n",
        "      initial[t] = initial.get(t, 0.) + 1\n",
        "    else:\n",
        "      t_1 = tokens[i-1]\n",
        "      if i == T - 1:\n",
        "        # measure probability of ending the line\n",
        "        add2dict(second_order, (t_1, t), 'END')\n",
        "      if i == 1:\n",
        "        # measure distribution of second word\n",
        "        # given only first word\n",
        "        add2dict(first_order, t_1, t)\n",
        "      else:\n",
        "        t_2 = tokens[i-2]\n",
        "        add2dict(second_order, (t_2, t_1), t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq98tbyWU7J5"
      },
      "source": [
        "# normalize the distributions\n",
        "initial_total = sum(initial.values())\n",
        "for t, c in initial.items():\n",
        "    initial[t] = c / initial_total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWr05mfxVBqH"
      },
      "source": [
        "# convert [cat, cat, cat, dog, dog, dog, dog, mouse, ...]\n",
        "# into {cat: 0.5, dog: 0.4, mouse: 0.1}\n",
        "\n",
        "def list2pdict(ts):\n",
        "  # turn each list of possibilities into a dictionary of probabilities\n",
        "  d = {}\n",
        "  n = len(ts)\n",
        "  for t in ts:\n",
        "    d[t] = d.get(t, 0.) + 1\n",
        "  for t, c in d.items():\n",
        "    d[t] = c / n\n",
        "  return d"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rR-QfKjZVMTC"
      },
      "source": [
        "for t_1, ts in first_order.items():\n",
        "  # replace list with dictionary of probabilities\n",
        "  first_order[t_1] = list2pdict(ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZC4AFs8VPZS"
      },
      "source": [
        "for k, ts in second_order.items():\n",
        "  second_order[k] = list2pdict(ts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oTSW8KwMVX8g"
      },
      "source": [
        "def sample_word(d):\n",
        "  # print \"d:\", d\n",
        "  p0 = np.random.random()\n",
        "  # print \"p0:\", p0\n",
        "  cumulative = 0\n",
        "  for t, p in d.items():\n",
        "    cumulative += p\n",
        "    if p0 < cumulative:\n",
        "      return t\n",
        "  assert(False) # should never get here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgLEb5NoVeUW"
      },
      "source": [
        "def generate():\n",
        "  for i in range(4): # generate 4 lines\n",
        "    sentence = []\n",
        "\n",
        "    # initial word\n",
        "    w0 = sample_word(initial)\n",
        "    sentence.append(w0)\n",
        "\n",
        "    # sample second word\n",
        "    w1 = sample_word(first_order[w0])\n",
        "    sentence.append(w1)\n",
        "\n",
        "    # second-order transitions until END\n",
        "    while True:\n",
        "      w2 = sample_word(second_order[(w0, w1)])\n",
        "      if w2 == 'END':\n",
        "        break\n",
        "      sentence.append(w2)\n",
        "      w0 = w1\n",
        "      w1 = w2\n",
        "    print(' '.join(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HnkxngVlVn7q",
        "outputId": "ba9aecbf-37e9-4a86-ca67-9fd2803348b4"
      },
      "source": [
        "generate()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first theres the childrens house of makebelieve\n",
            "are there they said it and besides\n",
            "and this bill\n",
            "my french indian esquimaux\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rqzv5F79Vps7"
      },
      "source": [
        "# Exercise:\n",
        "#\n",
        "# Determine the vocabulary size (V)\n",
        "# We know that pi has shape V, A1 has shape V x V, and A2 has shape V x V x V\n",
        "#\n",
        "# In comparison, how many values are stored in our dictionaries?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BQ3nEBnf69F7"
      },
      "source": [
        "# Exercise 2:\n",
        "# We can skip the step where we accumulate all the possible next words in a list\n",
        "# E.g. [cat, cat, dog, dog, dog, ...]\n",
        "#\n",
        "# Instead, like we do with the initial state distribution, create the dictionary\n",
        "# of counts directly as you loop through the data.\n",
        "#\n",
        "# You'll no longer need list2pdict()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}